{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"L7dZJ80EAeHF"},"outputs":[],"source":["import json\n","from pydub import AudioSegment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OueK4rVCAeHI"},"outputs":[],"source":["audiofile = '02. Learning in the Machine. Pierre Baldi.mp3'\n","audio = AudioSegment.from_mp3(audiofile)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SPTCKUnDAeHJ","outputId":"1ea7bcf3-8559-4baa-e1ce-4447b415643f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'text': \"chuga good morning so we're going to\", 'start': 11.3, 'duration': 5.55}, {'text': 'talk about deep learning the machine for', 'start': 14.24, 'duration': 6.449}, {'text': 'lack of a better word the machine of', 'start': 16.85, 'duration': 5.88}, {'text': 'course is the brain or a neuromorphic', 'start': 20.689, 'duration': 5.401}, {'text': \"chip what I really mean here it's a\", 'start': 22.73, 'duration': 6.599}, {'text': \"physical neural network it's not the\", 'start': 26.09, 'duration': 5.7}, {'text': 'fantasy that you use in your computer', 'start': 29.329, 'duration': 5.551}, {'text': \"when you're using tensorflow and doing\", 'start': 31.79, 'duration': 5.64}, {'text': 'ResNet or something like that that is', 'start': 34.88, 'duration': 5.01}, {'text': 'not a real native neural network right', 'start': 37.43, 'duration': 4.559}, {'text': \"you don't have synaptic weights you\", 'start': 39.89, 'duration': 4.2}, {'text': \"don't have neurons you have a fantasy of\", 'start': 41.989, 'duration': 4.291}, {'text': 'such objects implemented in a digital', 'start': 44.09, 'duration': 5.789}, {'text': 'computer and this makes a big difference', 'start': 46.28, 'duration': 7.829}, {'text': 'and I think there is a lot to be learned', 'start': 49.879, 'duration': 8.881}, {'text': 'by looking at deep learning in a native', 'start': 54.109, 'duration': 6.36}, {'text': 'neural network in a physical system', 'start': 58.76, 'duration': 5.22}, {'text': 'rather than in the digital simulation', 'start': 60.469, 'duration': 5.821}, {'text': 'and by taking into account the physical', 'start': 63.98, 'duration': 4.8}, {'text': 'constraints of the real world on the', 'start': 66.29, 'duration': 5.01}, {'text': 'real system I think we can get new', 'start': 68.78, 'duration': 5.4}, {'text': 'insights on the foundation of learning', 'start': 71.3, 'duration': 5.91}, {'text': 'and occasionally even find algorithms', 'start': 74.18, 'duration': 7.05}, {'text': 'that can improve deep learning on on', 'start': 77.21, 'duration': 8.28}, {'text': 'computers so all can we do this learning', 'start': 81.23, 'duration': 7.38}, {'text': 'in the machine well the solution was', 'start': 85.49, 'duration': 6.33}, {'text': 'found a long time ago by by Albert', 'start': 88.61, 'duration': 5.25}, {'text': 'Einstein if you walk a few hundred', 'start': 91.82, 'duration': 3.45}, {'text': 'meters from here there is Humboldt', 'start': 93.86, 'duration': 3.96}, {'text': \"University and that's where Einstein\", 'start': 95.27, 'duration': 4.5}, {'text': 'spent some time in fact if you walk', 'start': 97.82, 'duration': 3.72}, {'text': 'across the street I recommend you go see', 'start': 99.77, 'duration': 5.88}, {'text': 'there is a a glass plate on the on the', 'start': 101.54, 'duration': 5.85}, {'text': 'pavement through which you can see a', 'start': 105.65, 'duration': 5.82}, {'text': 'some some bookshelves and some books and', 'start': 107.39, 'duration': 6.96}, {'text': 'this is where the Nazi burned in 1933', 'start': 111.47, 'duration': 6.18}, {'text': 'burnt a lot of books from by Einstein', 'start': 114.35, 'duration': 6.75}, {'text': 'and then and many other great Jewish', 'start': 117.65, 'duration': 6.06}, {'text': 'scientists and and pacifist and so on', 'start': 121.1, 'duration': 4.8}, {'text': 'but anyway if you if you had met', 'start': 123.71, 'duration': 4.38}, {'text': 'Einstein a few hundred meters from here', 'start': 125.9, 'duration': 4.05}, {'text': 'and you would ask him how did he come up', 'start': 128.09, 'duration': 5.06}, {'text': 'with the theory of special relativity', 'start': 129.95, 'duration': 5.49}, {'text': 'everyone knows that he would have said', 'start': 133.15, 'duration': 5.41}, {'text': 'well I just try to think that I was a', 'start': 135.44, 'duration': 3.9}, {'text': 'ray of light', 'start': 138.56, 'duration': 4.38}, {'text': 'so basically imagination try to be a ray', 'start': 139.34, 'duration': 5.58}, {'text': 'of light try to think how the worlds', 'start': 142.94, 'duration': 2.31}, {'text': 'look', 'start': 144.92, 'duration': 2.91}, {'text': 'looks like if you are a photon so here', 'start': 145.25, 'duration': 4.38}, {'text': \"we're going to do the same thing we're\", 'start': 147.83, 'duration': 4.5}, {'text': 'going to try to think that try to think', 'start': 149.63, 'duration': 4.53}, {'text': \"that you're in Iran or try to think\", 'start': 152.33, 'duration': 4.62}, {'text': \"you're a synapse or an axon and ask\", 'start': 154.16, 'duration': 5.01}, {'text': 'yourself how would the world around you', 'start': 156.95, 'duration': 5.61}, {'text': \"look like so that's what we're going to\", 'start': 159.17, 'duration': 5.46}, {'text': \"do and I'm going to first give you a few\", 'start': 162.56, 'duration': 4.11}, {'text': 'simple examples of this style of', 'start': 164.63, 'duration': 4.68}, {'text': 'thinking for neurons but the place where', 'start': 166.67, 'duration': 4.14}, {'text': \"we're going to get I think some some\", 'start': 169.31, 'duration': 2.85}, {'text': 'interesting results is when we think', 'start': 170.81, 'duration': 4.11}, {'text': \"about synapses so here's the first\", 'start': 172.16, 'duration': 5.04}, {'text': 'example of this kind of thinking for a', 'start': 174.92, 'duration': 4.59}, {'text': \"simple neuron imagine you're doing\", 'start': 177.2, 'duration': 5.04}, {'text': 'logistic regression and I give you', 'start': 179.51, 'duration': 5.49}, {'text': 'binary vectors to be classified into', 'start': 182.24, 'duration': 5.46}, {'text': 'zero and ones and the binary vectors', 'start': 185.0, 'duration': 4.56}, {'text': 'that should be classified into ones are', 'start': 187.7, 'duration': 4.23}, {'text': 'those that are connected that is where', 'start': 189.56, 'duration': 4.62}, {'text': 'all the zeros are together and all the', 'start': 191.93, 'duration': 5.07}, {'text': 'ones are together with wraparound or not', 'start': 194.18, 'duration': 5.55}, {'text': \"that's the detail okay so that's the\", 'start': 197.0, 'duration': 4.62}, {'text': 'task and I ask you you know is this', 'start': 199.73, 'duration': 4.28}, {'text': 'simple is it is is it linearly separable', 'start': 201.62, 'duration': 5.76}, {'text': 'etc how does it compare to para', 'start': 204.01, 'duration': 6.94}, {'text': \"differences and if you're not used to\", 'start': 207.38, 'duration': 5.85}, {'text': 'this you may look at this and you may', 'start': 210.95, 'duration': 3.84}, {'text': 'think that this is a fairly simple task', 'start': 213.23, 'duration': 3.84}, {'text': 'compared to parity because parity you', 'start': 214.79, 'duration': 4.29}, {'text': 'have to look at all the bits and count', 'start': 217.07, 'duration': 3.449}, {'text': 'whether there is an even or odd number', 'start': 219.08, 'duration': 4.68}, {'text': 'of such bits whereas here you just look', 'start': 220.519, 'duration': 5.281}, {'text': 'at the pattern and you see immediately', 'start': 223.76, 'duration': 3.93}, {'text': 'whether the ones are clamped together or', 'start': 225.8, 'duration': 5.55}, {'text': \"not that's your thinking when you use\", 'start': 227.69, 'duration': 6.15}, {'text': 'your visual system but if now you put', 'start': 231.35, 'duration': 4.59}, {'text': 'yourself in the shoes of this neuron of', 'start': 233.84, 'duration': 4.23}, {'text': 'this little logistic regression the', 'start': 235.94, 'duration': 3.78}, {'text': 'world looks completely different', 'start': 238.07, 'duration': 4.5}, {'text': 'there is no sense that the first beat is', 'start': 239.72, 'duration': 5.25}, {'text': 'to the left of the second bit to the', 'start': 242.57, 'duration': 4.35}, {'text': 'left of the third bit etc that comes', 'start': 244.97, 'duration': 4.71}, {'text': 'only from the visual system in reality', 'start': 246.92, 'duration': 5.099}, {'text': 'this neuron has to learn the right', 'start': 249.68, 'duration': 5.73}, {'text': 'permutation of all the n bits in order', 'start': 252.019, 'duration': 4.921}, {'text': 'to solve this problem and so it turns', 'start': 255.41, 'duration': 5.88}, {'text': \"out it's a very hard problem and you get\", 'start': 256.94, 'duration': 6.81}, {'text': 'completely fooled by not thinking in the', 'start': 261.29, 'duration': 5.4}, {'text': 'machine another example of thinking in', 'start': 263.75, 'duration': 5.4}, {'text': 'the machine is dropout because you could', 'start': 266.69, 'duration': 4.26}, {'text': 'have again looked at the world from the', 'start': 269.15, 'duration': 5.49}, {'text': 'point of view of a neuron maybe you come', 'start': 270.95, 'duration': 5.399}, {'text': 'up with the idea that neurons are quite', 'start': 274.64, 'duration': 4.41}, {'text': \"faulty maybe they don't work 50 percent\", 'start': 276.349, 'duration': 4.29}, {'text': \"of the time so let's do that during\", 'start': 279.05, 'duration': 3.179}, {'text': \"learning and that's exactly what Drupal\", 'start': 280.639, 'duration': 4.801}, {'text': 'does you remove 50% or some other', 'start': 282.229, 'duration': 4.801}, {'text': 'fraction of your neurons during learning', 'start': 285.44, 'duration': 4.77}, {'text': 'you adjust the synapses and then another', 'start': 287.03, 'duration': 8.19}, {'text': 'group of neurons is removed etc you keep', 'start': 290.21, 'duration': 7.47}, {'text': 'repeating that so drop out you could', 'start': 295.22, 'duration': 4.949}, {'text': 'view it as a thinking in the machine', 'start': 297.68, 'duration': 5.489}, {'text': 'type type of thinking now note something', 'start': 300.169, 'duration': 4.801}, {'text': 'interesting when you do drop out at', 'start': 303.169, 'duration': 4.171}, {'text': 'production time your neurons are working', 'start': 304.97, 'duration': 4.59}, {'text': 'perfectly you just multiply the weights', 'start': 307.34, 'duration': 4.289}, {'text': 'by the probabilities of dropping and', 'start': 309.56, 'duration': 5.099}, {'text': \"that's it and so that maybe opens the\", 'start': 311.629, 'duration': 5.611}, {'text': 'door for having a better form of dropout', 'start': 314.659, 'duration': 4.891}, {'text': 'where you do drop out also at production', 'start': 317.24, 'duration': 4.979}, {'text': 'time and I think maybe you may gain a', 'start': 319.55, 'duration': 5.73}, {'text': 'very small amount in inaccuracy by doing', 'start': 322.219, 'duration': 4.471}, {'text': \"that nobody has done that but it's\", 'start': 325.28, 'duration': 3.21}, {'text': 'probably a very small effect it would', 'start': 326.69, 'duration': 4.379}, {'text': 'require at production time to just', 'start': 328.49, 'duration': 4.709}, {'text': 'average over a large number of networks', 'start': 331.069, 'duration': 4.53}, {'text': 'rather than doing the pseudo quick', 'start': 333.199, 'duration': 4.71}, {'text': 'average that you get by assuming that', 'start': 335.599, 'duration': 4.94}, {'text': 'all the neurons are working properly', 'start': 337.909, 'duration': 7.171}, {'text': \"so that's drop out other example of such\", 'start': 340.539, 'duration': 7.331}, {'text': \"thinking when you're looking at neurons\", 'start': 345.08, 'duration': 4.92}, {'text': 'would be for instance relaxing the', 'start': 347.87, 'duration': 4.019}, {'text': \"weight sharing assumption it's very\", 'start': 350.0, 'duration': 4.11}, {'text': 'unlikely that in biological networks you', 'start': 351.889, 'duration': 3.991}, {'text': 'have exact weight sharing for instance', 'start': 354.11, 'duration': 4.44}, {'text': 'right so all can you have a conclusion', 'start': 355.88, 'duration': 4.649}, {'text': 'neural network that works well if you', 'start': 358.55, 'duration': 5.519}, {'text': \"don't have exact weight sharing where\", 'start': 360.529, 'duration': 5.07}, {'text': 'you can show for instance that if you', 'start': 364.069, 'duration': 3.6}, {'text': 'take a convolutional Network and relax', 'start': 365.599, 'duration': 4.831}, {'text': 'the weight sharing assumption but you', 'start': 367.669, 'duration': 4.351}, {'text': 'initialize the weights sort of from from', 'start': 370.43, 'duration': 4.26}, {'text': 'the same typically from this zero mean', 'start': 372.02, 'duration': 4.47}, {'text': 'Gaussian with small standard deviation', 'start': 374.69, 'duration': 5.46}, {'text': 'you can get them to learn provided you', 'start': 376.49, 'duration': 5.429}, {'text': 'give them translated version of the', 'start': 380.15, 'duration': 4.35}, {'text': \"examples so that every neuron let's say\", 'start': 381.919, 'duration': 4.891}, {'text': 'in the first layer sees roughly the same', 'start': 384.5, 'duration': 5.699}, {'text': 'set of examples so these are just', 'start': 386.81, 'duration': 6.509}, {'text': 'examples of thinking in the machine from', 'start': 390.199, 'duration': 5.731}, {'text': 'the point of view of neurons now I want', 'start': 393.319, 'duration': 5.28}, {'text': 'to go to the point of view from from the', 'start': 395.93, 'duration': 4.139}, {'text': 'point of view of synapses which i think', 'start': 398.599, 'duration': 4.111}, {'text': 'is even more interesting and this is', 'start': 400.069, 'duration': 5.28}, {'text': 'among other things is going to help our', 'start': 402.71, 'duration': 5.699}, {'text': 'sense a question like what exactly is', 'start': 405.349, 'duration': 5.07}, {'text': 'again learning heavy learning is an', 'start': 408.409, 'duration': 4.321}, {'text': \"important concept but it's somewhat\", 'start': 410.419, 'duration': 4.891}, {'text': 'murky you know neuron that wire together', 'start': 412.73, 'duration': 4.47}, {'text': 'far together what what does that mean', 'start': 415.31, 'duration': 3.93}, {'text': 'exactly what is the relation between', 'start': 417.2, 'duration': 4.02}, {'text': 'avian learning and and back propagation', 'start': 419.24, 'duration': 4.74}, {'text': 'is back propagation hebbian for instance', 'start': 421.22, 'duration': 6.69}, {'text': 'a question that me seems and somewhat', 'start': 423.98, 'duration': 7.44}, {'text': 'strange but but important and why are', 'start': 427.91, 'duration': 5.31}, {'text': 'there so few learning algorithms because', 'start': 431.42, 'duration': 2.91}, {'text': 'really if you look at the literature', 'start': 433.22, 'duration': 3.21}, {'text': 'these are pretty much the only two', 'start': 434.33, 'duration': 4.71}, {'text': 'algorithms that are available for', 'start': 436.43, 'duration': 5.01}, {'text': 'training networks so why are there so', 'start': 439.04, 'duration': 6.75}, {'text': 'few algorithms so if we put ourselves in', 'start': 441.44, 'duration': 5.91}, {'text': 'their shoes imagine that that you are a', 'start': 445.79, 'duration': 5.36}, {'text': 'synapse the important thing I want to', 'start': 447.35, 'duration': 7.29}, {'text': 'impress on you is that to understand the', 'start': 451.15, 'duration': 5.38}, {'text': 'world of the synapse which is such a', 'start': 454.64, 'duration': 3.87}, {'text': 'small object you need to rescale things', 'start': 456.53, 'duration': 4.32}, {'text': 'so that they become more more palatable', 'start': 458.51, 'duration': 4.95}, {'text': \"to you so I'm going to rescale things by\", 'start': 460.85, 'duration': 5.4}, {'text': 'a factor of a million synapse is about', 'start': 463.46, 'duration': 5.28}, {'text': '10 to the minus 7 so you rescale it by a', 'start': 466.25, 'duration': 4.83}, {'text': \"million it's 10 to the minus 1 meters so\", 'start': 468.74, 'duration': 4.53}, {'text': 'about 10 centimeters the size of my fist', 'start': 471.08, 'duration': 5.01}, {'text': 'and imagine Einstein is learning how to', 'start': 473.27, 'duration': 5.34}, {'text': 'play the violin where is the bow of the', 'start': 476.09, 'duration': 4.65}, {'text': \"violin well it's maybe a 1 meter away\", 'start': 478.61, 'duration': 4.62}, {'text': 'which when you rescaled by 10 to the 6', 'start': 480.74, 'duration': 5.22}, {'text': \"that's thousand kilometers away so maybe\", 'start': 483.23, 'duration': 5.46}, {'text': 'in Paris right or Rome if your true', 'start': 485.96, 'duration': 5.85}, {'text': 'learning how to ride a bicycle so you', 'start': 488.69, 'duration': 5.13}, {'text': 'have these sign ups which is you know', 'start': 491.81, 'duration': 4.41}, {'text': 'embedded in these deep circuits in the', 'start': 493.82, 'duration': 4.74}, {'text': 'brain that has to decide whether to', 'start': 496.22, 'duration': 5.4}, {'text': 'strengthen itself or not or weaken', 'start': 498.56, 'duration': 6.2}, {'text': 'itself and then it has no notion of', 'start': 501.62, 'duration': 6.75}, {'text': 'music of violin etc right so how can it', 'start': 504.76, 'duration': 5.59}, {'text': 'do that and this is really the deep', 'start': 508.37, 'duration': 4.109}, {'text': 'learning problem when you think about it', 'start': 510.35, 'duration': 7.47}, {'text': \"in biological terms so that's just the\", 'start': 512.479, 'duration': 8.281}, {'text': 'rescaling so this leads immediately to', 'start': 517.82, 'duration': 4.65}, {'text': 'the notion of local learning because', 'start': 520.76, 'duration': 4.83}, {'text': 'sign ups in order to learn whatever the', 'start': 522.47, 'duration': 5.22}, {'text': 'learning rule is it has to depend on', 'start': 525.59, 'duration': 4.95}, {'text': 'local variables that are available in', 'start': 527.69, 'duration': 4.41}, {'text': 'the in the neighborhood of the of the', 'start': 530.54, 'duration': 5.91}, {'text': 'synapse so using this high level model', 'start': 532.1, 'duration': 6.6}, {'text': 'that you were using it means that you', 'start': 536.45, 'duration': 4.2}, {'text': 'one possible definition of local', 'start': 538.7, 'duration': 3.63}, {'text': 'learning would be to say that you have a', 'start': 540.65, 'duration': 4.08}, {'text': 'rule for adjusting your synaptic weights', 'start': 542.33, 'duration': 4.05}, {'text': 'which is some funk', 'start': 544.73, 'duration': 4.11}, {'text': 'of local variables such as the', 'start': 546.38, 'duration': 5.1}, {'text': 'presynaptic activity the post synaptic', 'start': 548.84, 'duration': 4.98}, {'text': 'activity and maybe the weight itself', 'start': 551.48, 'duration': 5.37}, {'text': \"that's a reasonable definition of what a\", 'start': 553.82, 'duration': 5.34}, {'text': 'local learning rule ought to be your', 'start': 556.85, 'duration': 4.17}, {'text': 'welcome to - to have your own definition', 'start': 559.16, 'duration': 4.38}, {'text': 'but within this formalism I think this', 'start': 561.02, 'duration': 5.55}, {'text': 'this is very reasonable now if you are', 'start': 563.54, 'duration': 4.2}, {'text': \"let's say you have a feed-forward\", 'start': 566.57, 'duration': 3.6}, {'text': 'Network you are in the output layer then', 'start': 567.74, 'duration': 4.26}, {'text': 'you may have targets so maybe the', 'start': 570.17, 'duration': 3.72}, {'text': 'targets could also be considered as', 'start': 572.0, 'duration': 4.68}, {'text': 'local variables in the output layer of', 'start': 573.89, 'duration': 6.6}, {'text': \"the feed-forward Network okay so that's\", 'start': 576.68, 'duration': 6.51}, {'text': 'the definition of a local learning rules', 'start': 580.49, 'duration': 5.25}, {'text': 'and I think this is nice because now you', 'start': 583.19, 'duration': 7.89}, {'text': 'can separate the variables that are in', 'start': 585.74, 'duration': 7.68}, {'text': 'the learning rule which need to be local', 'start': 591.08, 'duration': 4.74}, {'text': 'from the functional form of the learning', 'start': 593.42, 'duration': 5.07}, {'text': 'rules so I can decide what functional', 'start': 595.82, 'duration': 5.52}, {'text': 'form the function f should have for', 'start': 598.49, 'duration': 4.53}, {'text': 'instance we can work on polynomial', 'start': 601.34, 'duration': 4.41}, {'text': 'learning rules polynomials of low degree', 'start': 603.02, 'duration': 4.95}, {'text': 'maybe up to six that could be an', 'start': 605.75, 'duration': 4.89}, {'text': 'interesting set of function but in any', 'start': 607.97, 'duration': 4.92}, {'text': 'case we can stratify all possible', 'start': 610.64, 'duration': 6.54}, {'text': 'learning rules and we can study them one', 'start': 612.89, 'duration': 7.05}, {'text': 'by one so we did that for polynomial', 'start': 617.18, 'duration': 5.19}, {'text': 'learning rule of low degree for linear', 'start': 619.94, 'duration': 4.73}, {'text': 'neurons in some cases you can do also', 'start': 622.37, 'duration': 4.89}, {'text': 'nonlinear neurons and you can study all', 'start': 624.67, 'duration': 4.54}, {'text': 'these rules and their properties and', 'start': 627.26, 'duration': 4.14}, {'text': 'occasionally you can find rules that', 'start': 629.21, 'duration': 5.07}, {'text': 'have some interesting capabilities for', 'start': 631.4, 'duration': 5.55}, {'text': \"instance the order OSHA's rule which is\", 'start': 634.28, 'duration': 6.69}, {'text': '1/4 gruel actually can extract the', 'start': 636.95, 'duration': 6.6}, {'text': 'principal component of the data right so', 'start': 640.97, 'duration': 5.55}, {'text': 'these rules that you that you can study', 'start': 643.55, 'duration': 6.15}, {'text': 'can extract simple statistics of the of', 'start': 646.52, 'duration': 5.25}, {'text': 'the data such as the center of gravity', 'start': 649.7, 'duration': 5.64}, {'text': \"or the principal component so it's\", 'start': 651.77, 'duration': 5.28}, {'text': 'interesting to know that in which rules', 'start': 655.34, 'duration': 4.5}, {'text': 'converge etcetera but really what you', 'start': 657.05, 'duration': 5.61}, {'text': 'care about is learning by combining', 'start': 659.84, 'duration': 6.39}, {'text': 'these rules in a deep network so here', 'start': 662.66, 'duration': 5.4}, {'text': 'you have a deep feed-forward Network and', 'start': 666.23, 'duration': 3.78}, {'text': \"imagine that you're look using local\", 'start': 668.06, 'duration': 4.47}, {'text': 'rules in the first layer in the second', 'start': 670.01, 'duration': 5.63}, {'text': 'layer etc all the way to the top layer', 'start': 672.53, 'duration': 5.67}, {'text': 'in the top layer you can have targets', 'start': 675.64, 'duration': 4.15}, {'text': 'because the targets are available here', 'start': 678.2, 'duration': 1.83}, {'text': 'but', 'start': 679.79, 'duration': 2.01}, {'text': 'not of course in the deeper layers of', 'start': 680.03, 'duration': 4.17}, {'text': 'this feed-forward Network right and the', 'start': 681.8, 'duration': 4.5}, {'text': 'question is what can you do with this', 'start': 684.2, 'duration': 5.58}, {'text': 'system what can you learn this is', 'start': 686.3, 'duration': 6.03}, {'text': 'actually an old idea that goes back at', 'start': 689.78, 'duration': 6.12}, {'text': 'least to 1980 with Fukushima we who came', 'start': 692.33, 'duration': 5.19}, {'text': 'up with this architecture which is', 'start': 695.9, 'duration': 3.24}, {'text': 'nothing else than a convolutional neural', 'start': 697.52, 'duration': 4.26}, {'text': 'network inspired by the work of you will', 'start': 699.14, 'duration': 5.46}, {'text': 'visa let cetera but in slavery said well', 'start': 701.78, 'duration': 5.22}, {'text': 'we have adjustable ways between the', 'start': 704.6, 'duration': 4.62}, {'text': \"layers and we're going to learn using\", 'start': 707.0, 'duration': 5.67}, {'text': 'Habs rule some local learning rule have', 'start': 709.22, 'duration': 6.54}, {'text': 'is a special case of local learning well', 'start': 712.67, 'duration': 5.58}, {'text': 'no one has ever been able to to make', 'start': 715.76, 'duration': 4.56}, {'text': 'this work as far as I know and the', 'start': 718.25, 'duration': 5.07}, {'text': \"reason is that it cannot work so I'm\", 'start': 720.32, 'duration': 4.47}, {'text': 'going to tell you that if you stack', 'start': 723.32, 'duration': 2.82}, {'text': 'things like this in a feed-forward', 'start': 724.79, 'duration': 4.32}, {'text': 'Network you have data and you use head', 'start': 726.14, 'duration': 5.7}, {'text': 'rule or any local rule here here and', 'start': 729.11, 'duration': 5.43}, {'text': \"here and here etc you'll never be able\", 'start': 731.84, 'duration': 5.64}, {'text': 'to learn interesting functions and the', 'start': 734.54, 'duration': 5.01}, {'text': \"reason it's actually quite simple is if\", 'start': 737.48, 'duration': 4.79}, {'text': 'you want to be able to learn things a', 'start': 739.55, 'duration': 5.46}, {'text': 'reasonable condition for that is to say', 'start': 742.27, 'duration': 5.41}, {'text': 'you should be able to reach ideally', 'start': 745.01, 'duration': 4.59}, {'text': 'global minima your arrow function but', 'start': 747.68, 'duration': 3.81}, {'text': \"let's say at least critical points where\", 'start': 749.6, 'duration': 3.75}, {'text': 'well the gradient is zero so you write', 'start': 751.49, 'duration': 3.63}, {'text': 'the equation of the Grange at is equal', 'start': 753.35, 'duration': 3.99}, {'text': 'to zero those of you who know these', 'start': 755.12, 'duration': 4.35}, {'text': 'things well of course they understand', 'start': 757.34, 'duration': 3.6}, {'text': 'that this is just writing back', 'start': 759.47, 'duration': 4.44}, {'text': 'propagation equals zero so you can do it', 'start': 760.94, 'duration': 6.39}, {'text': 'by with you know large batches or just', 'start': 763.91, 'duration': 5.25}, {'text': \"the full training set so it's the\", 'start': 767.33, 'duration': 3.48}, {'text': 'average over the entire training set', 'start': 769.16, 'duration': 6.36}, {'text': \"let's say of the for a weight W IJ\", 'start': 770.81, 'duration': 8.49}, {'text': 'connecting neuron je2 neuron I in layer', 'start': 775.52, 'duration': 8.28}, {'text': \"H neuron J in layer H minus 1 it's the\", 'start': 779.3, 'duration': 6.87}, {'text': 'form of the presynaptic activity in', 'start': 783.8, 'duration': 5.16}, {'text': 'layer H minus 1 multiplied by the', 'start': 786.17, 'duration': 6.21}, {'text': 'postsynaptic back propagated error write', 'start': 788.96, 'duration': 7.62}, {'text': 'this back propagated error starts at the', 'start': 792.38, 'duration': 7.19}, {'text': 'top of the network depends on target -', 'start': 796.58, 'duration': 6.27}, {'text': 'output and then gets multiplied by all', 'start': 799.57, 'duration': 6.34}, {'text': 'the weights in the reverse direction in', 'start': 802.85, 'duration': 4.8}, {'text': 'back propagation all the weights of the', 'start': 805.91, 'duration': 4.2}, {'text': 'network in addition every time you', 'start': 807.65, 'duration': 4.14}, {'text': 'traverse a layer you multiply by the', 'start': 810.11, 'duration': 2.64}, {'text': 'derivative of', 'start': 811.79, 'duration': 3.66}, {'text': 'equations nonlinear activation functions', 'start': 812.75, 'duration': 5.55}, {'text': \"of the plate so it's reasonable to\", 'start': 815.45, 'duration': 5.34}, {'text': 'assume that the solution of to these', 'start': 818.3, 'duration': 4.56}, {'text': 'equations you have one such equation for', 'start': 820.79, 'duration': 3.54}, {'text': 'each weight so you may have a billion', 'start': 822.86, 'duration': 4.74}, {'text': 'equations right the solutions have to', 'start': 824.33, 'duration': 5.31}, {'text': 'depend for instance on the targets', 'start': 827.6, 'duration': 4.08}, {'text': 'because this term depends on the targets', 'start': 829.64, 'duration': 4.98}, {'text': 'might if you do this local learning in', 'start': 831.68, 'duration': 4.65}, {'text': 'feed-forward mode this again learning', 'start': 834.62, 'duration': 4.23}, {'text': 'apply layer by layer you see immediately', 'start': 836.33, 'duration': 4.5}, {'text': 'that the deep layer will never depend on', 'start': 838.85, 'duration': 6.18}, {'text': 'the targets and so you cannot learn such', 'start': 840.83, 'duration': 6.72}, {'text': 'function by the way in this term there', 'start': 845.03, 'duration': 5.25}, {'text': 'is also information about all the', 'start': 847.55, 'duration': 7.26}, {'text': \"weights above layer H and we'll come\", 'start': 850.28, 'duration': 6.69}, {'text': 'back to that because it would seem from', 'start': 854.81, 'duration': 3.6}, {'text': 'this equation that you need to know', 'start': 856.97, 'duration': 3.21}, {'text': 'everything about all the weights above', 'start': 858.41, 'duration': 4.41}, {'text': \"in order to find a solution and that's\", 'start': 860.18, 'duration': 4.71}, {'text': 'an important point that is actually not', 'start': 862.82, 'duration': 7.95}, {'text': 'true ok so have been learning or more', 'start': 864.89, 'duration': 8.4}, {'text': 'generally deeper local learning stacked', 'start': 870.77, 'duration': 4.53}, {'text': 'local learning in a feed-forward neural', 'start': 873.29, 'duration': 3.99}, {'text': 'network an author and complex functions', 'start': 875.3, 'duration': 5.67}, {'text': 'and so this leads to two new concept the', 'start': 877.28, 'duration': 6.48}, {'text': 'concept of deep learning channel and', 'start': 880.97, 'duration': 5.31}, {'text': 'local the local deep learning so what do', 'start': 883.76, 'duration': 5.73}, {'text': 'I mean by that well we have seen that a', 'start': 886.28, 'duration': 6.96}, {'text': 'deep weight has to depend on the targets', 'start': 889.49, 'duration': 6.39}, {'text': 'for instance right so there has to be a', 'start': 893.24, 'duration': 4.77}, {'text': 'channel it can be in a physical system', 'start': 895.88, 'duration': 4.89}, {'text': 'in the machine there has to be a channel', 'start': 898.01, 'duration': 5.19}, {'text': 'that conveys information about the', 'start': 900.77, 'duration': 4.53}, {'text': 'targets all the way down to the deep', 'start': 903.2, 'duration': 4.17}, {'text': 'weight there is no other way otherwise', 'start': 905.3, 'duration': 3.87}, {'text': 'you cannot solve those critical', 'start': 907.37, 'duration': 4.13}, {'text': 'equations and have the even weights', 'start': 909.17, 'duration': 7.95}, {'text': 'depend on the target okay so there has', 'start': 911.5, 'duration': 8.5}, {'text': 'to be this deep channel that conveys', 'start': 917.12, 'duration': 4.62}, {'text': 'information about the targets and other', 'start': 920.0, 'duration': 4.41}, {'text': \"things all the way from let's say the\", 'start': 921.74, 'duration': 5.82}, {'text': 'output back to the deep weights your', 'start': 924.41, 'duration': 6.09}, {'text': 'physical system your digital you know', 'start': 927.56, 'duration': 5.46}, {'text': \"simulation fantasy you don't worry about\", 'start': 930.5, 'duration': 4.29}, {'text': 'it but in a physical system you have to', 'start': 933.02, 'duration': 4.2}, {'text': 'worry about it and so we can ask for', 'start': 934.79, 'duration': 4.52}, {'text': 'instance where is the channel located', 'start': 937.22, 'duration': 4.92}, {'text': 'what kind of information does it carry', 'start': 939.31, 'duration': 5.14}, {'text': 'or what is the minimal amount of', 'start': 942.14, 'duration': 3.84}, {'text': 'information that it has to', 'start': 944.45, 'duration': 3.66}, {'text': 'arrey and what is the rate of the', 'start': 945.98, 'duration': 6.75}, {'text': 'channel etc all classical Shannon theory', 'start': 948.11, 'duration': 6.75}, {'text': 'of communication can be applied to this', 'start': 952.73, 'duration': 9.45}, {'text': 'to this object so if you think about the', 'start': 954.86, 'duration': 8.79}, {'text': 'brain if you think that you know', 'start': 962.18, 'duration': 3.24}, {'text': 'supervised learning is sort of a', 'start': 963.65, 'duration': 4.11}, {'text': 'reasonable approximation to some form of', 'start': 965.42, 'duration': 4.29}, {'text': \"biological learning what I'm telling you\", 'start': 967.76, 'duration': 4.47}, {'text': 'is that there has to be a channel that', 'start': 969.71, 'duration': 4.65}, {'text': 'goes all the way from from the motor', 'start': 972.23, 'duration': 4.98}, {'text': 'output or from wherever error functions', 'start': 974.36, 'duration': 5.34}, {'text': 'are computed all the way back to each', 'start': 977.21, 'duration': 4.65}, {'text': 'one of these synapses otherwise they', 'start': 979.7, 'duration': 8.21}, {'text': 'cannot they cannot learn and this is', 'start': 981.86, 'duration': 8.52}, {'text': 'important also because it shows that the', 'start': 987.91, 'duration': 5.02}, {'text': 'notion of feedback that you know the', 'start': 990.38, 'duration': 4.41}, {'text': 'word feedback is actually two completely', 'start': 992.93, 'duration': 3.21}, {'text': 'different meanings that have to be', 'start': 994.79, 'duration': 4.11}, {'text': 'separated there is one type of feedback', 'start': 996.14, 'duration': 5.28}, {'text': 'that is relatively fast that may occur', 'start': 998.9, 'duration': 4.68}, {'text': \"let's say in biological neurons on a\", 'start': 1001.42, 'duration': 6.42}, {'text': 'scale of 10 10 200 milliseconds for', 'start': 1003.58, 'duration': 6.96}, {'text': 'instance this visual system you know we', 'start': 1007.84, 'duration': 4.8}, {'text': 'often talk about feedback where you have', 'start': 1010.54, 'duration': 7.74}, {'text': 'a bottom-up sensory stream that meets a', 'start': 1012.64, 'duration': 8.34}, {'text': 'top-down expectation or modeling stream', 'start': 1018.28, 'duration': 5.13}, {'text': 'and together these two stream combines', 'start': 1020.98, 'duration': 5.16}, {'text': 'to spare to to stumble eyes your', 'start': 1023.41, 'duration': 5.34}, {'text': 'perception your percept of the world', 'start': 1026.14, 'duration': 4.62}, {'text': \"right that's the kind of feedback that\", 'start': 1028.75, 'duration': 4.8}, {'text': 'is sort of dynamical and very fast again', 'start': 1030.76, 'duration': 5.25}, {'text': 'on the scale of tens to 100 milliseconds', 'start': 1033.55, 'duration': 4.77}, {'text': \"here we're talking about deep learning\", 'start': 1036.01, 'duration': 4.95}, {'text': 'feedback the feedback for learning which', 'start': 1038.32, 'duration': 5.34}, {'text': 'can be much slower could be hours could', 'start': 1040.96, 'duration': 6.3}, {'text': 'be days and and could perhaps use the', 'start': 1043.66, 'duration': 5.4}, {'text': 'same pathways but also possibly', 'start': 1047.26, 'duration': 3.33}, {'text': 'completely different pathways we', 'start': 1049.06, 'duration': 3.45}, {'text': 'definitely know that in the brain you', 'start': 1050.59, 'duration': 5.16}, {'text': 'have tons of connections going into in', 'start': 1052.51, 'duration': 5.88}, {'text': 'the feedback direction but again two', 'start': 1055.75, 'duration': 6.2}, {'text': 'different possible notions of feedback', 'start': 1058.39, 'duration': 7.59}, {'text': \"so let's discuss first where can this\", 'start': 1061.95, 'duration': 7.68}, {'text': 'channel be in different neural systems', 'start': 1065.98, 'duration': 5.76}, {'text': 'again you see immediately that there is', 'start': 1069.63, 'duration': 3.67}, {'text': 'a number of possibilities you could have', 'start': 1071.74, 'duration': 4.8}, {'text': 'a system where signals can travel in', 'start': 1073.3, 'duration': 5.6}, {'text': 'both directions along axons', 'start': 1076.54, 'duration': 6.17}, {'text': 'right you can have systems where you', 'start': 1078.9, 'duration': 5.85}, {'text': 'have separate connections but they are', 'start': 1082.71, 'duration': 4.23}, {'text': 'sort of identical you use the transpose', 'start': 1084.75, 'duration': 4.309}, {'text': 'of the forward weights in the reverse', 'start': 1086.94, 'duration': 5.16}, {'text': 'this is sort of what you think when', 'start': 1089.059, 'duration': 5.681}, {'text': \"you're doing your digital fantasy in\", 'start': 1092.1, 'duration': 5.4}, {'text': \"your in your computer right that's the\", 'start': 1094.74, 'duration': 5.04}, {'text': 'way you think about it if you again if', 'start': 1097.5, 'duration': 3.87}, {'text': 'you think about biology many have', 'start': 1099.78, 'duration': 3.81}, {'text': \"pointed out it's it's very unlikely that\", 'start': 1101.37, 'duration': 4.14}, {'text': 'you have exact weights in the opposite', 'start': 1103.59, 'duration': 4.469}, {'text': 'direction right you could have a twin', 'start': 1105.51, 'duration': 5.19}, {'text': 'situation where you have a deep learning', 'start': 1108.059, 'duration': 4.441}, {'text': 'channel that has the same architecture', 'start': 1110.7, 'duration': 3.57}, {'text': \"as the forward but it's completely\", 'start': 1112.5, 'duration': 4.38}, {'text': 'separate but with the same architecture', 'start': 1114.27, 'duration': 5.88}, {'text': 'and then in my opinion the most', 'start': 1116.88, 'duration': 4.83}, {'text': 'plausible one is that you have a', 'start': 1120.15, 'duration': 3.27}, {'text': 'completely distinct channel that has', 'start': 1121.71, 'duration': 3.3}, {'text': 'different architecture and different', 'start': 1123.42, 'duration': 4.05}, {'text': 'numbers of neurons etc but of course', 'start': 1125.01, 'duration': 5.76}, {'text': 'which talks to the the forward pathway', 'start': 1127.47, 'duration': 6.089}, {'text': 'and through through different sets of', 'start': 1130.77, 'duration': 5.76}, {'text': \"weights and and that's what I call the\", 'start': 1133.559, 'duration': 6.961}, {'text': 'distinct case but for any physical', 'start': 1136.53, 'duration': 5.97}, {'text': 'system you can think about these', 'start': 1140.52, 'duration': 4.07}, {'text': 'different possibilities and what happens', 'start': 1142.5, 'duration': 5.7}, {'text': 'with learning with with rates etc in', 'start': 1144.59, 'duration': 9.25}, {'text': 'these different scenarios now one', 'start': 1148.2, 'duration': 7.77}, {'text': 'important result that was obtained by', 'start': 1153.84, 'duration': 5.37}, {'text': 'Lille crappy dog was that if you put', 'start': 1155.97, 'duration': 5.25}, {'text': 'completely random weights on the way', 'start': 1159.21, 'duration': 5.67}, {'text': 'back backpropagation still works which', 'start': 1161.22, 'duration': 6.209}, {'text': \"is somewhat amazing you don't need to\", 'start': 1164.88, 'duration': 4.86}, {'text': 'have the transpose of the forward weight', 'start': 1167.429, 'duration': 5.011}, {'text': 'on the deep Learning Channel you can', 'start': 1169.74, 'duration': 5.49}, {'text': 'have completely random matrices and if', 'start': 1172.44, 'duration': 4.98}, {'text': 'you do the simulation you see that it', 'start': 1175.23, 'duration': 6.15}, {'text': 'works almost as well as playing back', 'start': 1177.42, 'duration': 6.87}, {'text': \"propagation so that's a remarkable\", 'start': 1181.38, 'duration': 6.12}, {'text': 'result and it opens the door for doing a', 'start': 1184.29, 'duration': 5.79}, {'text': 'lot of studies on on these different', 'start': 1187.5, 'duration': 4.65}, {'text': 'architectures so you can do Studies on', 'start': 1190.08, 'duration': 4.47}, {'text': 'these different architectures using', 'start': 1192.15, 'duration': 5.82}, {'text': 'random weights on the backward pass but', 'start': 1194.55, 'duration': 6.48}, {'text': 'are not only that you can ask all kinds', 'start': 1197.97, 'duration': 4.5}, {'text': 'of questions on the backward pass', 'start': 1201.03, 'duration': 3.75}, {'text': 'typically you have a linear network all', 'start': 1202.47, 'duration': 3.839}, {'text': 'the operations you do are matrix', 'start': 1204.78, 'duration': 3.42}, {'text': 'multiplication you multiply maybe by the', 'start': 1206.309, 'duration': 5.101}, {'text': 'derivatives etc why should the backward', 'start': 1208.2, 'duration': 4.51}, {'text': 'channel be linear', 'start': 1211.41, 'duration': 3.28}, {'text': 'and the forward pass channel be', 'start': 1212.71, 'duration': 5.31}, {'text': 'nonlinear right you may want in a', 'start': 1214.69, 'duration': 5.07}, {'text': 'physical system use the same kind of', 'start': 1218.02, 'duration': 4.19}, {'text': 'hardware in both directions so you may', 'start': 1219.76, 'duration': 5.549}, {'text': 'try to have nonlinear neurons in the', 'start': 1222.21, 'duration': 5.77}, {'text': \"Learning Channel you'd like to use\", 'start': 1225.309, 'duration': 4.98}, {'text': 'dropout on the forward Channel why not', 'start': 1227.98, 'duration': 7.26}, {'text': 'use drop out on the backward Channel you', 'start': 1230.289, 'duration': 7.38}, {'text': 'like run sparse matrices maybe we want', 'start': 1235.24, 'duration': 4.38}, {'text': 'to use sparse matrices in the backward', 'start': 1237.669, 'duration': 6.211}, {'text': 'channel random sparse matrices and what', 'start': 1239.62, 'duration': 6.0}, {'text': 'about these derivatives do you really', 'start': 1243.88, 'duration': 4.14}, {'text': 'need to multiply by the derivatives of', 'start': 1245.62, 'duration': 4.11}, {'text': 'the forward channel in the backward', 'start': 1248.02, 'duration': 3.18}, {'text': 'Channel do you need all the derivatives', 'start': 1249.73, 'duration': 5.87}, {'text': 'just the riveters of the current layers', 'start': 1251.2, 'duration': 4.4}, {'text': 'you adjust the weights in the forward', 'start': 1255.69, 'duration': 5.709}, {'text': 'channel by head happen back propagation', 'start': 1258.279, 'duration': 4.981}, {'text': 'become essentially the same once you', 'start': 1261.399, 'duration': 4.26}, {'text': 'have the backward learning channel but', 'start': 1263.26, 'duration': 4.83}, {'text': 'why not adapt also the weights in the', 'start': 1265.659, 'duration': 5.25}, {'text': 'backward Channel maybe if they are made', 'start': 1268.09, 'duration': 4.62}, {'text': 'of the same hardware you should be used', 'start': 1270.909, 'duration': 3.87}, {'text': 'hapur back propagation in both channels', 'start': 1272.71, 'duration': 3.719}, {'text': 'in the forward Channel and the deep', 'start': 1274.779, 'duration': 5.13}, {'text': 'learning channel and if you look at this', 'start': 1276.429, 'duration': 5.191}, {'text': 'architecture you can also have skipped', 'start': 1279.909, 'duration': 4.531}, {'text': 'connections like this in fact you can', 'start': 1281.62, 'duration': 4.529}, {'text': 'have an architecture that has only skip', 'start': 1284.44, 'duration': 2.91}, {'text': 'connections where basically you have', 'start': 1286.149, 'duration': 2.821}, {'text': 'connections running from the top layer', 'start': 1287.35, 'duration': 4.439}, {'text': 'back to all the different layers so', 'start': 1288.97, 'duration': 5.13}, {'text': \"that's what we call it fully skipped\", 'start': 1291.789, 'duration': 5.581}, {'text': 'architectures so you see that you end up', 'start': 1294.1, 'duration': 6.079}, {'text': 'with lots of you know possibilities and', 'start': 1297.37, 'duration': 5.22}, {'text': \"we've tried all of them essentially\", 'start': 1300.179, 'duration': 5.081}, {'text': 'maybe a hundred or 200 simulations of', 'start': 1302.59, 'duration': 4.68}, {'text': 'all the combinations and the main', 'start': 1305.26, 'duration': 3.6}, {'text': 'results is that the deep learning', 'start': 1307.27, 'duration': 4.08}, {'text': 'channel is very robust that is most of', 'start': 1308.86, 'duration': 5.37}, {'text': 'these combinations they work or you can', 'start': 1311.35, 'duration': 5.189}, {'text': 'get them to work they may be a little', 'start': 1314.23, 'duration': 3.9}, {'text': 'harder to get to work than back then', 'start': 1316.539, 'duration': 3.961}, {'text': 'playing back propagation but if you', 'start': 1318.13, 'duration': 4.11}, {'text': 'spend some time tweaking the learning', 'start': 1320.5, 'duration': 4.26}, {'text': 'rate etc you can get most of them to', 'start': 1322.24, 'duration': 5.22}, {'text': 'work there is a couple of them that do', 'start': 1324.76, 'duration': 5.399}, {'text': 'not work for instance if you get rid of', 'start': 1327.46, 'duration': 4.17}, {'text': \"all the derivatives you don't multiply\", 'start': 1330.159, 'duration': 3.39}, {'text': 'by any derivative in the deep learning', 'start': 1331.63, 'duration': 3.96}, {'text': \"channel then you won't be able to learn\", 'start': 1333.549, 'duration': 5.1}, {'text': 'well you do need those derivatives in', 'start': 1335.59, 'duration': 5.459}, {'text': 'fact you you can show even more than', 'start': 1338.649, 'duration': 4.831}, {'text': 'that you only need the derivative of the', 'start': 1341.049, 'duration': 4.561}, {'text': \"capital of the current layers you don't\", 'start': 1343.48, 'duration': 3.05}, {'text': 'need the derivative', 'start': 1345.61, 'duration': 2.51}, {'text': 'above the current layer like', 'start': 1346.53, 'duration': 3.69}, {'text': 'backpropagation does backpropagation use', 'start': 1348.12, 'duration': 4.41}, {'text': 'all the derivatives above you actually', 'start': 1350.22, 'duration': 4.14}, {'text': \"don't need all of them if you have a\", 'start': 1352.53, 'duration': 3.69}, {'text': 'skipped architecture you can get rid of', 'start': 1354.36, 'duration': 3.84}, {'text': 'all those derivatives and but you will', 'start': 1356.22, 'duration': 3.92}, {'text': 'need the derivative of the current layer', 'start': 1358.2, 'duration': 4.89}, {'text': 'and also another thing that is important', 'start': 1360.14, 'duration': 7.75}, {'text': 'that you see also in when you do the', 'start': 1363.09, 'duration': 6.93}, {'text': 'work of lily craft is that the random', 'start': 1367.89, 'duration': 4.98}, {'text': 'weights start here so they play a role', 'start': 1370.02, 'duration': 6.45}, {'text': 'in learning for the layer before the', 'start': 1372.87, 'duration': 5.55}, {'text': 'last one but the last layer is doing', 'start': 1376.47, 'duration': 3.75}, {'text': \"gradient descent and that's that's\", 'start': 1378.42, 'duration': 3.81}, {'text': 'absolutely necessary if you remove the', 'start': 1380.22, 'duration': 4.14}, {'text': 'gradient descent from the top layer then', 'start': 1382.23, 'duration': 4.17}, {'text': 'all these algorithms start to break down', 'start': 1384.36, 'duration': 5.91}, {'text': 'I can show you some example of', 'start': 1386.4, 'duration': 6.21}, {'text': 'simulation on NIST or safar so these are', 'start': 1390.27, 'duration': 5.73}, {'text': \"example of DC's back propagation this is\", 'start': 1392.61, 'duration': 6.3}, {'text': 'skipped back propagation skipped random', 'start': 1396.0, 'duration': 5.07}, {'text': 'back propagation random back propagation', 'start': 1398.91, 'duration': 5.61}, {'text': 'this is without the derivatives etc you', 'start': 1401.07, 'duration': 5.01}, {'text': 'can see that they all converge at', 'start': 1404.52, 'duration': 3.24}, {'text': 'different speeds but they all converge', 'start': 1406.08, 'duration': 3.84}, {'text': 'we should remove the derivatives these', 'start': 1407.76, 'duration': 4.11}, {'text': 'guys are not learning this is the', 'start': 1409.92, 'duration': 6.63}, {'text': 'training set this is the test set this', 'start': 1411.87, 'duration': 6.6}, {'text': 'is another set of experiment where we', 'start': 1416.55, 'duration': 3.93}, {'text': 'look at an adaptive random back', 'start': 1418.47, 'duration': 3.78}, {'text': \"propagation so we're adapting the\", 'start': 1420.48, 'duration': 4.62}, {'text': 'weights both on the forward channel and', 'start': 1422.25, 'duration': 5.07}, {'text': 'on the deep learning channel using the', 'start': 1425.1, 'duration': 4.23}, {'text': 'same rule you know product of the', 'start': 1427.32, 'duration': 6.54}, {'text': 'presynaptic and postsynaptic error if', 'start': 1429.33, 'duration': 7.38}, {'text': 'you want so to speak training set set', 'start': 1433.86, 'duration': 5.43}, {'text': 'you can see they all converge to two', 'start': 1436.71, 'duration': 5.48}, {'text': 'good performance etc etcetera these are', 'start': 1439.29, 'duration': 5.28}, {'text': 'experiment done with sparse random', 'start': 1442.19, 'duration': 4.63}, {'text': 'matrices with different level sparsity', 'start': 1444.57, 'duration': 8.94}, {'text': 'etc same thing same thing on c4 this is', 'start': 1446.82, 'duration': 7.74}, {'text': 'just to show you an interesting', 'start': 1453.51, 'duration': 3.36}, {'text': 'technique for some simulation that comes', 'start': 1454.56, 'duration': 5.58}, {'text': 'from paper by by Sabatini at all what', 'start': 1456.87, 'duration': 4.83}, {'text': 'you have at the top is your data so', 'start': 1460.14, 'duration': 3.48}, {'text': 'there is a mathematical function that as', 'start': 1461.7, 'duration': 4.2}, {'text': 'a parameter K that allows you to adjust', 'start': 1463.62, 'duration': 5.43}, {'text': 'the complexity of the data so with k', 'start': 1465.9, 'duration': 6.15}, {'text': 'equal 1 this is your data k equal to', 'start': 1469.05, 'duration': 5.61}, {'text': \"it's like this etc so as K grows you\", 'start': 1472.05, 'duration': 5.16}, {'text': 'have more and more black dots in this', 'start': 1474.66, 'duration': 4.29}, {'text': 'picture right the picture becomes more', 'start': 1477.21, 'duration': 3.18}, {'text': 'and more complicated', 'start': 1478.95, 'duration': 4.92}, {'text': 'to do with Betty numbers and basically', 'start': 1480.39, 'duration': 5.58}, {'text': 'the task of your network is you give it', 'start': 1483.87, 'duration': 5.19}, {'text': 'as input to values x and y and the', 'start': 1485.97, 'duration': 4.32}, {'text': 'output is the prediction the', 'start': 1489.06, 'duration': 3.21}, {'text': 'classification blue black and white and', 'start': 1490.29, 'duration': 5.01}, {'text': 'these networks here have even layer size', 'start': 1492.27, 'duration': 4.98}, {'text': '500 and there is maybe four or five', 'start': 1495.3, 'duration': 4.71}, {'text': 'hidden layers and back propagation is', 'start': 1497.25, 'duration': 5.04}, {'text': 'here you know is able to learn very well', 'start': 1500.01, 'duration': 4.74}, {'text': 'the patterns this is the data this is', 'start': 1502.29, 'duration': 4.77}, {'text': 'what back propagation produces and these', 'start': 1504.75, 'duration': 4.11}, {'text': 'are some of the other algorithm for', 'start': 1507.06, 'duration': 4.11}, {'text': 'instance random back propagation and you', 'start': 1508.86, 'duration': 4.89}, {'text': 'see that at low complexity it matches', 'start': 1511.17, 'duration': 4.77}, {'text': 'the data and back propagation very well', 'start': 1513.75, 'duration': 5.25}, {'text': 'at high complexity of the same you know', 'start': 1515.94, 'duration': 5.85}, {'text': \"training at the same a pokey it's a\", 'start': 1519.0, 'duration': 4.95}, {'text': 'little bit behind and there are', 'start': 1521.79, 'duration': 3.42}, {'text': 'variations across the different', 'start': 1523.95, 'duration': 3.27}, {'text': \"algorithms this one doesn't seem to be\", 'start': 1525.21, 'duration': 4.65}, {'text': 'doing very well but you know again', 'start': 1527.22, 'duration': 4.74}, {'text': 'tweaking learning rate etc you can get', 'start': 1529.86, 'duration': 4.17}, {'text': 'even this one after a while to look', 'start': 1531.96, 'duration': 9.03}, {'text': 'exactly like this so now I want to tell', 'start': 1534.03, 'duration': 8.82}, {'text': 'you about what needs to be communicated', 'start': 1540.99, 'duration': 6.24}, {'text': 'in in this channel and basically you can', 'start': 1542.85, 'duration': 6.93}, {'text': 'see that you can reduce the amount of', 'start': 1547.23, 'duration': 4.26}, {'text': 'information that is needed from the', 'start': 1549.78, 'duration': 3.9}, {'text': 'critical equation you get the impression', 'start': 1551.49, 'duration': 4.59}, {'text': 'that you need to transmit you know the', 'start': 1553.68, 'duration': 4.56}, {'text': 'targets the output all the weights above', 'start': 1556.08, 'duration': 4.56}, {'text': 'all the weights below and all the', 'start': 1558.24, 'duration': 5.88}, {'text': 'derivatives above that propagation alone', 'start': 1560.64, 'duration': 5.73}, {'text': 'already tells you that you only need in', 'start': 1564.12, 'duration': 4.86}, {'text': \"fact to send T - oh you don't need to\", 'start': 1566.37, 'duration': 6.51}, {'text': \"send T a no separately you don't need\", 'start': 1568.98, 'duration': 6.57}, {'text': 'all the weights below in fact the only', 'start': 1572.88, 'duration': 5.82}, {'text': 'thing you need is is the activity of the', 'start': 1575.55, 'duration': 5.49}, {'text': 'presynaptic neurons so all the weight', 'start': 1578.7, 'duration': 4.53}, {'text': 'all the information about all the', 'start': 1581.04, 'duration': 5.49}, {'text': 'weights below is subsumed by the', 'start': 1583.23, 'duration': 6.48}, {'text': 'activity of the presynaptic neurons', 'start': 1586.53, 'duration': 5.73}, {'text': 'this by the way suggests that it should', 'start': 1589.71, 'duration': 4.32}, {'text': 'be the same for all the weights above', 'start': 1592.26, 'duration': 4.47}, {'text': \"you really don't need to know everything\", 'start': 1594.03, 'duration': 5.01}, {'text': 'about all the weights above in the same', 'start': 1596.73, 'duration': 3.93}, {'text': \"way that you don't need to know about\", 'start': 1599.04, 'duration': 4.38}, {'text': 'all the weights below and this is', 'start': 1600.66, 'duration': 6.6}, {'text': 'exactly what leads and nnh is shown by', 'start': 1603.42, 'duration': 5.67}, {'text': 'random back propagation because random', 'start': 1607.26, 'duration': 3.48}, {'text': 'like propagation has completely random', 'start': 1609.09, 'duration': 4.98}, {'text': 'weights in the layer above to the lay', 'start': 1610.74, 'duration': 8.07}, {'text': \"that you're trying to to learn and then\", 'start': 1614.07, 'duration': 6.69}, {'text': 'we skip the random back propagation we', 'start': 1618.81, 'duration': 3.39}, {'text': \"see that we don't need all the\", 'start': 1620.76, 'duration': 3.78}, {'text': 'derivatives of the layers above you just', 'start': 1622.2, 'duration': 5.39}, {'text': 'need the derivative of the current layer', 'start': 1624.54, 'duration': 6.24}, {'text': 'so basically what what it seems what', 'start': 1627.59, 'duration': 4.93}, {'text': 'seems to work the minimal amount of', 'start': 1630.78, 'duration': 4.26}, {'text': 'things that you need to send is some', 'start': 1632.52, 'duration': 6.75}, {'text': 'function of T - Oh a linear a random', 'start': 1635.04, 'duration': 7.44}, {'text': \"matrix of T - so we'll work a random\", 'start': 1639.27, 'duration': 6.78}, {'text': 'sparse matrix will work you can reduce', 'start': 1642.48, 'duration': 6.33}, {'text': 'the precision on T - so quite a bit not', 'start': 1646.05, 'duration': 5.31}, {'text': 'down to one bit if you do just one beat', 'start': 1648.81, 'duration': 4.53}, {'text': \"the sine of T - so it doesn't seem to\", 'start': 1651.36, 'duration': 4.59}, {'text': 'work but a low precision version of T -', 'start': 1653.34, 'duration': 5.85}, {'text': 'so try me random sparse matrix will work', 'start': 1655.95, 'duration': 7.46}, {'text': 'plus the Riveter of the current layer', 'start': 1659.19, 'duration': 4.22}, {'text': 'you may guess that if you multiply this', 'start': 1664.37, 'duration': 5.71}, {'text': 'by a matrix it would have to be a full', 'start': 1667.44, 'duration': 5.79}, {'text': \"rank matrix and it's five minutes left\", 'start': 1670.08, 'duration': 5.43}, {'text': \"it's it's it's about right but it's not\", 'start': 1673.23, 'duration': 4.05}, {'text': 'a sharp threshold that is if the random', 'start': 1675.51, 'duration': 4.02}, {'text': 'matrix is full rank it works well if', 'start': 1677.28, 'duration': 5.13}, {'text': \"it's one rank below the full rank\", 'start': 1679.53, 'duration': 6.39}, {'text': 'it will feel sort of learn not there', 'start': 1682.41, 'duration': 4.98}, {'text': 'will be graceful degradation in', 'start': 1685.92, 'duration': 3.78}, {'text': 'performance there will not be a complete', 'start': 1687.39, 'duration': 5.49}, {'text': 'collapse so does those our simulation', 'start': 1689.7, 'duration': 5.67}, {'text': 'results can we prove anything well we', 'start': 1692.88, 'duration': 4.38}, {'text': 'can start with very simple networks this', 'start': 1695.37, 'duration': 3.87}, {'text': 'is a simple linear network for instance', 'start': 1697.26, 'duration': 5.31}, {'text': 'with two two layers in this case three', 'start': 1699.24, 'duration': 5.91}, {'text': 'layers you have weights a and B on the', 'start': 1702.57, 'duration': 5.85}, {'text': 'forward the channel weight C in the deep', 'start': 1705.15, 'duration': 5.94}, {'text': 'reverse channel and you can write down', 'start': 1708.42, 'duration': 6.63}, {'text': 'the equations of such a system in fact', 'start': 1711.09, 'duration': 6.18}, {'text': 'some of this is in in the lily crop', 'start': 1715.05, 'duration': 5.1}, {'text': 'paper we have extended the theorem a', 'start': 1717.27, 'duration': 4.77}, {'text': 'little bit but you can see that the', 'start': 1720.15, 'duration': 4.41}, {'text': 'stable points are given by these', 'start': 1722.04, 'duration': 5.22}, {'text': 'hyperbolas here where the products of', 'start': 1724.56, 'duration': 5.34}, {'text': 'the weights a and b is some constant the', 'start': 1727.26, 'duration': 5.28}, {'text': 'right constant and you can see in these', 'start': 1729.9, 'duration': 4.47}, {'text': 'phase space as all these points are', 'start': 1732.54, 'duration': 4.05}, {'text': 'attractors all the arrows are converging', 'start': 1734.37, 'duration': 4.14}, {'text': 'if you start here you have a parabolic', 'start': 1736.59, 'duration': 5.1}, {'text': 'trajectory that ends up here and here is', 'start': 1738.51, 'duration': 4.86}, {'text': 'the same thing except for this little', 'start': 1741.69, 'duration': 7.7}, {'text': 'piece of this a parabola where action', 'start': 1743.37, 'duration': 6.02}, {'text': 'the points are unstable and and the', 'start': 1749.76, 'duration': 6.18}, {'text': 'trajectories tend to diverge from those', 'start': 1754.049, 'duration': 3.961}, {'text': 'points but they will converge on some', 'start': 1755.94, 'duration': 4.199}, {'text': 'other points on those on those I propose', 'start': 1758.01, 'duration': 5.34}, {'text': 'so for that very simple system you can', 'start': 1760.139, 'duration': 5.311}, {'text': 'understand what happens but of course', 'start': 1763.35, 'duration': 3.959}, {'text': 'you would like to understand more', 'start': 1765.45, 'duration': 3.75}, {'text': 'complex system even in the linear case', 'start': 1767.309, 'duration': 4.141}, {'text': 'you could have a multi-layer linear', 'start': 1769.2, 'duration': 4.29}, {'text': 'network all these are matrices forward', 'start': 1771.45, 'duration': 4.709}, {'text': 'matrices you have random matrices on the', 'start': 1773.49, 'duration': 5.25}, {'text': 'way back whether you do it in the skete', 'start': 1776.159, 'duration': 4.441}, {'text': 'fashion as drawn here or in the', 'start': 1778.74, 'duration': 3.929}, {'text': \"propagation faction it's essentially\", 'start': 1780.6, 'duration': 4.919}, {'text': 'equivalent and if you write the learning', 'start': 1782.669, 'duration': 5.401}, {'text': 'equation for the matrices a you get', 'start': 1785.519, 'duration': 5.16}, {'text': \"essentially this thing because it's very\", 'start': 1788.07, 'duration': 4.849}, {'text': \"easy to see that because it's just the\", 'start': 1790.679, 'duration': 5.61}, {'text': 'transpose of the of the stream coming', 'start': 1792.919, 'duration': 5.531}, {'text': 'from the forward pathway which is this', 'start': 1796.289, 'duration': 5.041}, {'text': 'object here there is a input transpose', 'start': 1798.45, 'duration': 5.699}, {'text': 'here and then there is the the feedback', 'start': 1801.33, 'duration': 6.78}, {'text': 'matrix ci times the what is at the top T', 'start': 1804.149, 'duration': 6.811}, {'text': '- so when it combines with the input you', 'start': 1808.11, 'duration': 4.71}, {'text': 'get this this quantity here so this is', 'start': 1810.96, 'duration': 5.25}, {'text': 'the covariance matrix of the targets', 'start': 1812.82, 'duration': 6.06}, {'text': 'with respect to the inputs P is the', 'start': 1816.21, 'duration': 5.01}, {'text': 'product of all the matrices and this is', 'start': 1818.88, 'duration': 4.35}, {'text': 'the covariance matrix of the input data', 'start': 1821.22, 'duration': 5.429}, {'text': 'if your backward the pathway is also', 'start': 1823.23, 'duration': 5.429}, {'text': 'adaptive you get these equations for', 'start': 1826.649, 'duration': 4.681}, {'text': 'adapting the C so you get a huge system', 'start': 1828.659, 'duration': 4.921}, {'text': 'of differential equations and just for', 'start': 1831.33, 'duration': 4.41}, {'text': 'comparison these are the system that you', 'start': 1833.58, 'duration': 6.51}, {'text': 'get for for back propagation so can we', 'start': 1835.74, 'duration': 7.14}, {'text': 'solve such systems well in general no', 'start': 1840.09, 'duration': 4.38}, {'text': 'these are actually very complicated', 'start': 1842.88, 'duration': 4.56}, {'text': 'systems these are polynomial systems of', 'start': 1844.47, 'duration': 7.47}, {'text': 'differential equations and if you are in', 'start': 1847.44, 'duration': 7.41}, {'text': 'one dimension if you have DX DT equal P', 'start': 1851.94, 'duration': 5.459}, {'text': 'of X that we understand qualitatively', 'start': 1854.85, 'duration': 5.49}, {'text': 'quite well I will show you an example at', 'start': 1857.399, 'duration': 4.321}, {'text': 'the very end but basically you cannot', 'start': 1860.34, 'duration': 3.78}, {'text': 'have oscillations you either converging', 'start': 1861.72, 'duration': 4.23}, {'text': 'two fixed points or divergence to', 'start': 1864.12, 'duration': 4.019}, {'text': 'infinity but if you have two', 'start': 1865.95, 'duration': 5.729}, {'text': 'differential equations DX DT equal P of', 'start': 1868.139, 'duration': 8.431}, {'text': 'X Y dy DT equal Q of X Y just two', 'start': 1871.679, 'duration': 7.5}, {'text': 'equations with two polynomial that is', 'start': 1876.57, 'duration': 4.53}, {'text': 'extremely difficult in', 'start': 1879.179, 'duration': 5.101}, {'text': \"fact Hilbert's 16 problem is the\", 'start': 1881.1, 'duration': 5.189}, {'text': 'question of whether you can bound the', 'start': 1884.28, 'duration': 4.17}, {'text': 'number of limits cycle of such a system', 'start': 1886.289, 'duration': 4.981}, {'text': 'and that question is completely unsolved', 'start': 1888.45, 'duration': 5.52}, {'text': \"Steve's mail wrote a paper fifteen years\", 'start': 1891.27, 'duration': 5.34}, {'text': \"ago the new version of Hilbert's problem\", 'start': 1893.97, 'duration': 5.43}, {'text': \"for the 21st century it's in there and\", 'start': 1896.61, 'duration': 4.8}, {'text': 'basically no progress has been made on', 'start': 1899.4, 'duration': 4.05}, {'text': \"this question for for many decades it's\", 'start': 1901.41, 'duration': 5.07}, {'text': 'a little bit like a P equal NP so these', 'start': 1903.45, 'duration': 4.77}, {'text': 'are problems are very difficult but in', 'start': 1906.48, 'duration': 4.05}, {'text': 'some restricted cases we can solve them', 'start': 1908.22, 'duration': 4.68}, {'text': 'for instance if you have a long chain of', 'start': 1910.53, 'duration': 5.7}, {'text': 'very deep chain of units that are all', 'start': 1912.9, 'duration': 4.95}, {'text': \"linear I'll show you this at the very\", 'start': 1916.23, 'duration': 5.25}, {'text': 'end if you have a system with one unit', 'start': 1917.85, 'duration': 5.64}, {'text': 'and units in the even layer than one', 'start': 1921.48, 'duration': 4.62}, {'text': 'unit this guy here we can solve etc', 'start': 1923.49, 'duration': 5.87}, {'text': 'there are interesting connections to two', 'start': 1926.1, 'duration': 6.329}, {'text': 'complex ideas in algebraic geometry like', 'start': 1929.36, 'duration': 6.64}, {'text': \"Kozue complex I won't go into that and\", 'start': 1932.429, 'duration': 5.581}, {'text': 'in some cases you can solve the the', 'start': 1936.0, 'duration': 4.61}, {'text': 'nonlinear case for instance if you have', 'start': 1938.01, 'duration': 5.19}, {'text': 'the case with three units like this', 'start': 1940.61, 'duration': 4.54}, {'text': 'where you put a non-linearity here like', 'start': 1943.2, 'duration': 4.979}, {'text': 'a a power function for instance that', 'start': 1945.15, 'duration': 5.19}, {'text': 'case we can solve and show that it', 'start': 1948.179, 'duration': 4.951}, {'text': 'converge so just to finish let me show', 'start': 1950.34, 'duration': 4.38}, {'text': 'you what happens in this case so these', 'start': 1953.13, 'duration': 3.419}, {'text': 'two problems are equivalent again the', 'start': 1954.72, 'duration': 3.54}, {'text': 'the skipped version versus the', 'start': 1956.549, 'duration': 3.451}, {'text': 'propagated version are equivalent so', 'start': 1958.26, 'duration': 3.149}, {'text': \"let's stick with the skipped version\", 'start': 1960.0, 'duration': 4.08}, {'text': 'what you have here is a chain of linear', 'start': 1961.409, 'duration': 5.13}, {'text': 'neurons everything is linear if I give', 'start': 1964.08, 'duration': 4.829}, {'text': 'you an input it gets multiplied by a 1 a', 'start': 1966.539, 'duration': 6.39}, {'text': \"2 al so the output is a 1 a 2 a I'll\", 'start': 1968.909, 'duration': 6.451}, {'text': \"time the input let's call P the product\", 'start': 1972.929, 'duration': 4.921}, {'text': \"of all these weights obviously you're\", 'start': 1975.36, 'duration': 3.99}, {'text': \"trying to learn what's the right\", 'start': 1977.85, 'duration': 3.059}, {'text': \"combination of weight so you're\", 'start': 1979.35, 'duration': 8.1}, {'text': 'adjusting a line and very simple problem', 'start': 1980.909, 'duration': 8.971}, {'text': \"it's even convex but each one of these\", 'start': 1987.45, 'duration': 4.64}, {'text': \"little weights it's applying its own\", 'start': 1989.88, 'duration': 4.61}, {'text': 'learning rule based on this random', 'start': 1992.09, 'duration': 5.05}, {'text': 'feedback weights CL these these weights', 'start': 1994.49, 'duration': 5.59}, {'text': 'are fixed but completely random so if', 'start': 1997.14, 'duration': 4.529}, {'text': 'you write the differential equations', 'start': 2000.08, 'duration': 3.599}, {'text': \"they look like this that's a system of\", 'start': 2001.669, 'duration': 4.231}, {'text': 'differential equations that is satisfied', 'start': 2003.679, 'duration': 6.151}, {'text': 'by this large set of weights if you look', 'start': 2005.9, 'duration': 5.64}, {'text': 'carefully you can see that any two', 'start': 2009.83, 'duration': 3.78}, {'text': 'consecutive equations are coupled in', 'start': 2011.54, 'duration': 3.3}, {'text': 'this way', 'start': 2013.61, 'duration': 3.24}, {'text': 'which means that the evolution of AI', 'start': 2014.84, 'duration': 5.87}, {'text': 'plus one is the quadratic function of AI', 'start': 2016.85, 'duration': 6.75}, {'text': 'right so a two is a quadratic function', 'start': 2020.71, 'duration': 7.089}, {'text': 'of a 1 a 3 is the quadratic function of', 'start': 2023.6, 'duration': 7.23}, {'text': \"a - so it's aquatic function of a 1 etc\", 'start': 2027.799, 'duration': 6.48}, {'text': 'etc so basically you can take the', 'start': 2030.83, 'duration': 6.63}, {'text': 'equation of a 1 you can write a 1 there', 'start': 2034.279, 'duration': 4.74}, {'text': 'is the product P of all the AI you', 'start': 2037.46, 'duration': 4.74}, {'text': \"replace each AI as it's a function of a\", 'start': 2039.019, 'duration': 5.76}, {'text': \"1 it's a you know large polynomial of\", 'start': 2042.2, 'duration': 5.52}, {'text': 'the grid yi of even degree and you end', 'start': 2044.779, 'duration': 4.681}, {'text': 'up with an equation that looks like this', 'start': 2047.72, 'duration': 5.82}, {'text': 'they da 1 DT equals a big polynomial of', 'start': 2049.46, 'duration': 6.959}, {'text': 'a 1 and if you look carefully the', 'start': 2053.54, 'duration': 7.68}, {'text': 'polynomial is of degree 2 n minus 1 so', 'start': 2056.419, 'duration': 7.41}, {'text': \"it's an odd polynomial with an odd\", 'start': 2061.22, 'duration': 4.74}, {'text': 'degree and a negative leading', 'start': 2063.829, 'duration': 5.34}, {'text': 'coefficient so it is something that', 'start': 2065.96, 'duration': 8.79}, {'text': 'looks like this right and so if you', 'start': 2069.169, 'duration': 8.611}, {'text': 'start anywhere suppose you start here it', 'start': 2074.75, 'duration': 5.129}, {'text': \"says the riveted is negative so you're\", 'start': 2077.78, 'duration': 3.539}, {'text': \"going to move like this and you're going\", 'start': 2079.879, 'duration': 3.871}, {'text': 'to end up to this fixed point here right', 'start': 2081.319, 'duration': 4.951}, {'text': 'if you start here the same thing the', 'start': 2083.75, 'duration': 4.26}, {'text': \"derivative is positive so you're going\", 'start': 2086.27, 'duration': 8.069}, {'text': 'to end up here now if you start here at', 'start': 2088.01, 'duration': 9.27}, {'text': 'minus infinity or your derivative is', 'start': 2094.339, 'duration': 4.861}, {'text': \"positive so you're going to move and end\", 'start': 2097.28, 'duration': 4.079}, {'text': 'up here and the same thing here if you', 'start': 2099.2, 'duration': 4.409}, {'text': 'start here your derivative is negative', 'start': 2101.359, 'duration': 3.901}, {'text': \"so you're going to move to the left and\", 'start': 2103.609, 'duration': 4.051}, {'text': 'ended up here so no matter where you', 'start': 2105.26, 'duration': 2.849}, {'text': 'start', 'start': 2107.66, 'duration': 3.03}, {'text': 'this system is converge convergent and', 'start': 2108.109, 'duration': 5.25}, {'text': 'will converge to the right solution so', 'start': 2110.69, 'duration': 4.23}, {'text': 'although you have completely random', 'start': 2113.359, 'duration': 3.841}, {'text': 'weights in the feedback channel although', 'start': 2114.92, 'duration': 4.98}, {'text': 'these could have a million layers by', 'start': 2117.2, 'duration': 4.95}, {'text': 'magic this system will always converge', 'start': 2119.9, 'duration': 8.04}, {'text': \"to a correct solution ok I'm out of time\", 'start': 2122.15, 'duration': 9.03}, {'text': 'so let me summarize learning the machine', 'start': 2127.94, 'duration': 5.61}, {'text': 'is looks at learning in physical neural', 'start': 2131.18, 'duration': 4.77}, {'text': 'system not in the digital fantasy that', 'start': 2133.55, 'duration': 8.279}, {'text': 'that we use thinking about the about', 'start': 2135.95, 'duration': 8.099}, {'text': 'synaptic synapses and their environment', 'start': 2141.829, 'duration': 4.01}, {'text': 'leads to the notion of local learning', 'start': 2144.049, 'duration': 4.661}, {'text': 'the rules for adjusting', 'start': 2145.839, 'duration': 4.821}, {'text': 'synaptic weights should depend only on', 'start': 2148.71, 'duration': 4.889}, {'text': 'local variables this leads to the notion', 'start': 2150.66, 'duration': 5.699}, {'text': 'of deep learning channel if you depend', 'start': 2153.599, 'duration': 4.441}, {'text': 'only a local variable and you have a', 'start': 2156.359, 'duration': 3.811}, {'text': 'feed-forward network you will never be', 'start': 2158.04, 'duration': 5.069}, {'text': 'able to learn anything interesting you', 'start': 2160.17, 'duration': 6.27}, {'text': 'need a backward Channel the deep', 'start': 2163.109, 'duration': 6.24}, {'text': 'learning channel to communicate', 'start': 2166.44, 'duration': 4.95}, {'text': 'information about the targets all the', 'start': 2169.349, 'duration': 4.081}, {'text': 'way to the deep weights the deep', 'start': 2171.39, 'duration': 3.81}, {'text': 'learning channel appears to be in', 'start': 2173.43, 'duration': 4.37}, {'text': 'simulation very robust to all kinds of', 'start': 2175.2, 'duration': 4.5}, {'text': 'perturbation and variations in', 'start': 2177.8, 'duration': 6.94}, {'text': 'algorithms in topology etc etc we have', 'start': 2179.7, 'duration': 7.619}, {'text': 'sort of corner what is the minimal', 'start': 2184.74, 'duration': 4.98}, {'text': 'information that is required to enable', 'start': 2187.319, 'duration': 5.401}, {'text': 'learning in deep synapses and in some', 'start': 2189.72, 'duration': 6.119}, {'text': 'cases we can build a mathematical theory', 'start': 2192.72, 'duration': 5.49}, {'text': 'but ultimately this leads this area', 'start': 2195.839, 'duration': 4.22}, {'text': 'leads to systems of polynomial', 'start': 2198.21, 'duration': 5.19}, {'text': 'differential equations which are quite', 'start': 2200.059, 'duration': 11.441}, {'text': 'difficult to solve thank you other', 'start': 2203.4, 'duration': 10.189}, {'text': 'questions', 'start': 2211.5, 'duration': 2.089}, {'text': 'I am a very interesting that basically', 'start': 2219.68, 'duration': 8.29}, {'text': 'showed that this robustness is there in', 'start': 2225.81, 'duration': 5.16}, {'text': 'this learning rules what I wonder is', 'start': 2227.97, 'duration': 4.95}, {'text': 'what is the gap in performance that you', 'start': 2230.97, 'duration': 5.55}, {'text': 'get if you go away from the classical', 'start': 2232.92, 'duration': 5.73}, {'text': 'backpropagation Marja see here in these', 'start': 2236.52, 'duration': 6.87}, {'text': 'simulations yes you know typically the', 'start': 2238.65, 'duration': 6.69}, {'text': 'top curve is back propagation so this', 'start': 2243.39, 'duration': 4.86}, {'text': 'may be honest so in 20 a poker back', 'start': 2245.34, 'duration': 4.77}, {'text': 'propagation is essentially a hundred', 'start': 2248.25, 'duration': 5.61}, {'text': 'percent and skipped or random back', 'start': 2250.11, 'duration': 7.05}, {'text': 'propagation maybe up 95 or 96 so you see', 'start': 2253.86, 'duration': 5.73}, {'text': \"it's a little bit slower but ultimately\", 'start': 2257.16, 'duration': 5.07}, {'text': 'it gets there I mean why I ask is', 'start': 2259.59, 'duration': 4.53}, {'text': 'because waiting reinforcement learning', 'start': 2262.23, 'duration': 3.63}, {'text': 'with the temple different thing you also', 'start': 2264.12, 'duration': 3.87}, {'text': 'work with noisy gradients at one point', 'start': 2265.86, 'duration': 6.21}, {'text': \"and empirically it is that it's noisy\", 'start': 2267.99, 'duration': 5.4}, {'text': 'greatest cost you something in', 'start': 2272.07, 'duration': 3.96}, {'text': 'performance in training time do you', 'start': 2273.39, 'duration': 6.23}, {'text': 'think that this can be related here', 'start': 2276.03, 'duration': 3.59}, {'text': 'possibly possibly I mean force for', 'start': 2280.49, 'duration': 4.78}, {'text': 'simple system like the one the long', 'start': 2283.29, 'duration': 4.47}, {'text': 'chain we we sort of know how long it', 'start': 2285.27, 'duration': 4.83}, {'text': 'takes for the system to converge so we', 'start': 2287.76, 'duration': 4.56}, {'text': 'can compare what happens with random', 'start': 2290.1, 'duration': 5.61}, {'text': 'weights in the backward pass where if', 'start': 2292.32, 'duration': 5.19}, {'text': 'you use the transpose of the forward', 'start': 2295.71, 'duration': 4.38}, {'text': 'weights compare the two and then we we', 'start': 2297.51, 'duration': 5.43}, {'text': 'can get some some scaling there but', 'start': 2300.09, 'duration': 5.07}, {'text': \"there is no phone I don't expect that\", 'start': 2302.94, 'duration': 4.16}, {'text': 'there is any any fundamental difference', 'start': 2305.16, 'duration': 8.55}, {'text': 'okay thank you so yeah my first question', 'start': 2307.1, 'duration': 8.05}, {'text': \"I guess it's answered already about the\", 'start': 2313.71, 'duration': 5.22}, {'text': 'speed of convergence so what happens', 'start': 2315.15, 'duration': 6.24}, {'text': 'when you try it on m-miss one of these', 'start': 2318.93, 'duration': 6.23}, {'text': 'data sets what you see in the curve yeah', 'start': 2321.39, 'duration': 6.84}, {'text': 'so back propagation may converge in', 'start': 2325.16, 'duration': 6.25}, {'text': 'twenty airports and one of the other', 'start': 2328.23, 'duration': 5.52}, {'text': 'variants may take 50 or 100 iBooks', 'start': 2331.41, 'duration': 4.92}, {'text': 'but you will get there in reasonable', 'start': 2333.75, 'duration': 8.09}, {'text': 'time yeah max', 'start': 2336.33, 'duration': 5.51}, {'text': 'so as a follow-up what about the world', 'start': 2341.9, 'duration': 4.68}, {'text': 'clock time I guess with randomized', 'start': 2344.72, 'duration': 4.32}, {'text': 'weights you kind of say some computation', 'start': 2346.58, 'duration': 4.98}, {'text': 'so but you need longer time for', 'start': 2349.04, 'duration': 4.2}, {'text': 'convergence so does it end up at the', 'start': 2351.56, 'duration': 5.31}, {'text': 'same war-club time roughly or is it so', 'start': 2353.24, 'duration': 5.49}, {'text': \"it's their time to get some speed\", 'start': 2356.87, 'duration': 4.08}, {'text': \"improvement if I don't if you use random\", 'start': 2358.73, 'duration': 4.05}, {'text': \"wait ya know you'll be slower\", 'start': 2360.95, 'duration': 5.52}, {'text': \"you don't improve your speed you mean\", 'start': 2362.78, 'duration': 6.87}, {'text': 'your your speed of conversion terms of a', 'start': 2366.47, 'duration': 5.73}, {'text': 'box but I need to do less computation', 'start': 2369.65, 'duration': 4.86}, {'text': \"right I guess because I don't need to\", 'start': 2372.2, 'duration': 5.34}, {'text': 'compute the gradient well you still have', 'start': 2374.51, 'duration': 4.71}, {'text': 'to if you use the random matrices you', 'start': 2377.54, 'duration': 3.51}, {'text': 'see left to multiply by random matrices', 'start': 2379.22, 'duration': 3.81}, {'text': 'multiplied by derivative multiplied by', 'start': 2381.05, 'duration': 3.9}, {'text': 'random matrices so you should do you', 'start': 2383.03, 'duration': 3.78}, {'text': 'know standard back propagation with', 'start': 2384.95, 'duration': 4.26}, {'text': 'random weights the number of calculation', 'start': 2386.81, 'duration': 3.66}, {'text': \"is the same it's just that you're using\", 'start': 2389.21, 'duration': 5.04}, {'text': 'random weights instead of using you know', 'start': 2390.47, 'duration': 6.98}, {'text': 'the transpose of the forward matrices', 'start': 2394.25, 'duration': 7.23}, {'text': 'here have you have you studied you know', 'start': 2397.45, 'duration': 6.55}, {'text': 'what kind of randomness you should be', 'start': 2401.48, 'duration': 6.66}, {'text': \"using like it's very robust what process\", 'start': 2404.0, 'duration': 6.09}, {'text': 'have you changed process yeah we change', 'start': 2408.14, 'duration': 6.54}, {'text': 'process you know again we we tried so of', 'start': 2410.09, 'duration': 6.75}, {'text': 'course Gaussian but then we tried sparse', 'start': 2414.68, 'duration': 7.4}, {'text': \"matrices with coin flips mmm that's fine\", 'start': 2416.84, 'duration': 5.24}, {'text': \"I'm not so much varied about convergence\", 'start': 2423.67, 'duration': 6.25}, {'text': 'speeds but I would be interested if you', 'start': 2427.13, 'duration': 4.92}, {'text': 'would use this to not single networks', 'start': 2429.92, 'duration': 4.92}, {'text': 'but ensembles of such networks with', 'start': 2432.05, 'duration': 4.86}, {'text': 'random back propagation type weights', 'start': 2434.84, 'duration': 5.19}, {'text': 'whether these would have potentially a', 'start': 2436.91, 'duration': 6.39}, {'text': 'better performance and say an average of', 'start': 2440.03, 'duration': 5.37}, {'text': 'simply back propagated neural networks I', 'start': 2443.3, 'duration': 5.13}, {'text': 'see maybe a little bit relationships we', 'start': 2445.4, 'duration': 5.25}, {'text': 'know random weights that convert convey', 'start': 2448.43, 'duration': 4.14}, {'text': 'information back to maybe human', 'start': 2450.65, 'duration': 3.93}, {'text': 'creativity where maybe you need to make', 'start': 2452.57, 'duration': 5.76}, {'text': 'an error to find a good solution yeah so', 'start': 2454.58, 'duration': 5.91}, {'text': \"I haven't tried to do an ensemble of\", 'start': 2458.33, 'duration': 4.74}, {'text': 'back propagations but we have done drop', 'start': 2460.49, 'duration': 4.8}, {'text': 'out on the way back which is a little', 'start': 2463.07, 'duration': 4.71}, {'text': \"bit like averaging an ensemble we don't\", 'start': 2465.29, 'duration': 4.68}, {'text': \"see you know any any but it doesn't hurt\", 'start': 2467.78, 'duration': 4.08}, {'text': \"you but it doesn't buy you anything\", 'start': 2469.97, 'duration': 3.93}, {'text': 'obvious at least in in the simulations', 'start': 2471.86, 'duration': 4.37}, {'text': 'of with', 'start': 2473.9, 'duration': 2.33}, {'text': 'so I can you can use for example', 'start': 2480.63, 'duration': 4.8}, {'text': 'message-passing to train the layers of', 'start': 2482.64, 'duration': 4.979}, {'text': 'networker or more general you can use', 'start': 2485.43, 'duration': 3.99}, {'text': 'projection and inferential for example', 'start': 2487.619, 'duration': 4.591}, {'text': 'you complete a posterior distribution', 'start': 2489.42, 'duration': 5.399}, {'text': 'given they input the computer posterior', 'start': 2492.21, 'duration': 5.1}, {'text': 'distribution given the target and then', 'start': 2494.819, 'duration': 4.891}, {'text': 'try to match the two distributions in', 'start': 2497.31, 'duration': 4.92}, {'text': 'the six for example a variational a tan', 'start': 2499.71, 'duration': 4.95}, {'text': 'color would work and also D projection', 'start': 2502.23, 'duration': 3.93}, {'text': 'art and color will have a very similar', 'start': 2504.66, 'duration': 3.36}, {'text': 'structure to the one you propose with', 'start': 2506.16, 'duration': 4.199}, {'text': 'the encoding network decoding networking', 'start': 2508.02, 'duration': 4.62}, {'text': 'skip connections between the two so was', 'start': 2510.359, 'duration': 4.201}, {'text': 'wondering is there any way of making a', 'start': 2512.64, 'duration': 4.56}, {'text': 'formal connection between variational', 'start': 2514.56, 'duration': 4.74}, {'text': 'inference and what they are trying to do', 'start': 2517.2, 'duration': 5.28}, {'text': 'here possibly', 'start': 2519.3, 'duration': 8.97}, {'text': \"I will haven't really thought about it\", 'start': 2522.48, 'duration': 11.19}, {'text': 'but there because in a way so innovation', 'start': 2528.27, 'duration': 7.68}, {'text': 'I think color for example you will get a', 'start': 2533.67, 'duration': 5.34}, {'text': 'feedback which is exerted a quantitative', 'start': 2535.95, 'duration': 4.919}, {'text': 'information we can you can actually', 'start': 2539.01, 'duration': 4.079}, {'text': 'measure in not so and you use that', 'start': 2540.869, 'duration': 4.441}, {'text': 'quantity of information to correct and', 'start': 2543.089, 'duration': 5.041}, {'text': 'update your layers so it feels very much', 'start': 2545.31, 'duration': 6.65}, {'text': 'like with your string to the year yeah', 'start': 2548.13, 'duration': 3.83}, {'text': 'painful one last question just raising', 'start': 2552.56, 'duration': 6.7}, {'text': 'the question so when does it fail it', 'start': 2557.52, 'duration': 4.349}, {'text': 'cannot always work okay right so I gave', 'start': 2559.26, 'duration': 5.7}, {'text': 'some example where it fails for instance', 'start': 2561.869, 'duration': 5.761}, {'text': \"if you don't have if on The Learning\", 'start': 2564.96, 'duration': 4.77}, {'text': 'Channel you completely forget the', 'start': 2567.63, 'duration': 4.739}, {'text': 'derivatives well you put random matrices', 'start': 2569.73, 'duration': 4.589}, {'text': 'or even the transpose of the main of the', 'start': 2572.369, 'duration': 3.661}, {'text': \"forward matrices but you don't x\", 'start': 2574.319, 'duration': 5.401}, {'text': \"derivatives then it doesn't work but as\", 'start': 2576.03, 'duration': 6.17}, {'text': 'an example in terms of applications this', 'start': 2579.72, 'duration': 5.099}, {'text': 'so the data sets you have tried it', 'start': 2582.2, 'duration': 5.95}, {'text': 'always seem to work the variations that', 'start': 2584.819, 'duration': 5.851}, {'text': 'work yes they work on c far data we try', 'start': 2588.15, 'duration': 4.65}, {'text': 'nominees we tried on another data set', 'start': 2590.67, 'duration': 7.05}, {'text': \"that I didn't show yes some are more\", 'start': 2592.8, 'duration': 6.93}, {'text': 'finicky you know they require more i', 'start': 2597.72, 'duration': 5.52}, {'text': 'programmer tuning but digital just', 'start': 2599.73, 'duration': 5.16}, {'text': 'adapting the last layer I mean this is', 'start': 2603.24, 'duration': 3.9}, {'text': 'echo state if you adapt only the last', 'start': 2604.89, 'duration': 3.58}, {'text': 'layer on on addy', 'start': 2607.14, 'duration': 6.52}, {'text': 'functioning South God worked it stinks', 'start': 2608.47, 'duration': 7.16}, {'text': 'to speak you again', 'start': 2613.66, 'duration': 6.479}, {'text': '[Applause]', 'start': 2615.63, 'duration': 4.509}]\n"]}],"source":["file = open('02. Learning in the Machine. Pierre Baldi.json')\n","file = json.load(file)\n","print(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FS-WQOCVAeHK","outputId":"f3e0ba0a-24c0-436f-a91b-76f7e2c22538"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'text': \"chuga good morning so we're going to\", 'start': 11.3, 'duration': 5.55}\n"]}],"source":["print(file[0])\n","durs = []\n","#start = file[0]['start']\n","for i in file:\n","    start = i['start']\n","    end = start + i['duration']\n","    audiochunk = audio[start:end]\n","    audiochunk.export(f\"audio_data/02. Learning in the Machine. Pierre Baldi{start}-{end}.wav\", format='wav')"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.10 ('cs178')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"38c762ab130bd88fd467ed819ac0e6ce94c03cd3cf47821307e691fea32fd23e"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}